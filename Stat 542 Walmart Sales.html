
<!-- saved from url=(1082)https://piazza-resources.s3.amazonaws.com/jky28ddlhmu2r8/jn12q355sd52hn/Stat_542_Walmart_Sales.html?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=ASIAR6AWVCBXQP2U7HM2%2F20190103%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20190103T002443Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Security-Token=FQoGZXIvYXdzEJj%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaDJpwdCGl1jPiw26AYCK3A3HIeOhcwAekXK8c0lmrbx5Rd7GlSoAUHtS6mx19modED6jWW1oLbpqXgBgkbVgViPZ6FOy8QkJeDd7DJw0f3l538gmyTHjQClMqI%2Bf9y4VIz1tLQhzxYBFxiq7LKxmGtrR7%2BfQSMJWxf3Fi7sTfFPO56%2FyYU9aCD7n2N8PvlcOoLi5J6uzRRdg3J5AKPv2rllSE8h%2FqqDwQ%2BdcydvnNyZqh2N3kbXmS%2F04DGalGkRK4Ku%2BPLTDk%2Bj2dHS9GPv89oKoQrsidMdkgaRBpG5rs48vmVmirko0f6r8NjNrLCH%2BBTGMtPUrTQYMsv0xTE8YBHZ97bPBE0eGsUVDMVk30JKzW5J%2BnmxYQmV7Mut7l0bsKcuN4M%2By398N5ppnmcsEzqazMMZtQ9EnEKQpuLHoeJvUJ0moKDfmhwOfjLxQEiA5EALlyfLTSIPXjMTjJcd2VZNl1LbOYP6%2BJIF%2BwD8wrtRF816NF3zjTrPSb4hFMKMAmNgfdXW1cmVEw9j1yc3QkS3OxNwe1qxHD%2BNqf84D7utF8V2lB8rruYxOzcg8kVSH9aAJNzpKcwHX1nEW8NyTQIEiCMOPuGaso1O604QU%3D&X-Amz-Signature=d12c1e36ed2b731e163750b9af187bc3edcc82adc5a1a00170ddf3c64ac72d39 -->
<html class="gr__piazza-resources_s3_amazonaws_com"><head><meta http-equiv="Content-Type" content="text/html; charset=windows-1252"> 
<title> Stat 542 Walmart Sales</title> 

<style type="text/css"> 
body {
 margin-right: 50px;
 margin-left: 50px;
 margin-top: auto;
 width: 680px;
 font-size: 14px;
 font-family: Verdana, Eyechart, Geneve, Arial, Helvetica, sans-serif;
 color: black;
 background-color: #FFFFDE;
}

h2 {
/*font-family: Georgia, "MS Serif", "New York", serif; */
    font-family: Georgia, "Times New Roman", Times, serif;
    font-variant: small-caps;
    color: #aa3300;
}

h4 {
    font-family: Georgia, "Times New Roman", Times, serif;
    color: #003366;
    font-variant: small-caps;
    font-weight: bold;
    font-size: 16px;
}

h3 {
    font-family: Georgia, "Times New Roman", Times, serif;
    color: #aa3300;
    font-variant: small-caps;
    font-weight: bold;
    font-size: 18px;
}
big {
 font-size: larger;
}                                 

small {
 font-family: times;
 font-size: 10pt;
    }


a:link {
background: transparent;
color : #ff6600;
text-decoration : none;
}
a:visited {
background: transparent;
color: #ff6600;
text-decoration : underline;
}

a:hover {
background: transparent;
color: #999999;
text-decoration : underline;
}

a:active {
background: transparent;
color: #ff6600;
text-decoration : underline;
}

pre {
display: block; 
   font-family: "courier new", courier, monospace;
background-color: EBECE4;
xwidth = 60%;
}
</style>


</head>
<body data-gr-c-s-loaded="true">

<hr>

<h4><span style="color: #aa3300;"> Project 2: Walmart Stores Forcasting</span></h4>


You are provided with historical sales data for 45 Walmart stores
located in different regions. Each store contains many departments. The goal is to predict the future weekly
sales for each department in each store based on the historical data.

<div>
<dl><dt><b>Source</b><br><br></dt>
<dd> You can find the data (only train.csv), relevant information, and some sample code
  on Kaggle (<a href="https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting" target="_blank">https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting</a>). Note that  <b>ONLY</b> the training data is used in this project and our evaluation procedure is <b>different</b> from the one on Kaggle. 

<br><br></dd>

<dt><b> What you need to submit? </b><br><br></dt><dd>
</dd><dd>  Before the deadline (<font color="blue">Thursday, November 8, 11:30PM, Pacific Time </font>), please submit the following two items (one copy per team) to  the corresponding assignment box on Compass: 
 <ul>
   <li> <span style="text-decoration: underline;">R/Python
   code</span><br> (.R or .py or zip; details are given below); <br><br>
   </li><li> <span style="text-decoration: underline;">A report</span><br>
   (3 pages maximum, pdf only) that provides the details of your code,
   e.g., pre-processing, some technical details or implementation
   details (if not trivial) of the models you use, etc.<br><br>
   
   In addition, In addition, report  the accuracy (see evaluation metric given below), running time of your code and the computer system you use (e.g., Macbook Pro, 2.53 GHz, 4GB memory, or AWS t2.large). You <b>DO NOT</b> need to submit the part of the code related to the evaluation you conduct.
   </li></ul>

</dd><dt><b>How we evaluate your code? </b><br><br></dt>
<dd> The initial train.csv file you'll be provided has the weekly sales data
  for all stores and departments from 2010-02 (February 2010) to 2011-02
  (February 2011), which takes the same format as the
  train.csv file on Kaggle (see the FAQ section).  <br><br>

  Then you'll be asked to predict the weekly
  sales for each department in each store for the next two month,
  starting from 2011-03 to 2012-10 (20 months in total). <br><br>

  For example, based on the
  the data till 2011-02, you need to predict the weekly sales
for 2011-03 and 2011-04, then you'll be provided with the weekly sales
  data for 2011-03 and 2011-04, and next you need to predict the weekly sales
for 2011-05 and 2011-06, and so on. <br><br>

Our evaluation procedure is formulated like backtesting for stock trading systems: when predicting the sales of a month, you are only allowed to use all the information available till that month --- you cannot peek into the future. <br><br>

 Name your main file as <b>mymain.R</b>. If you have multiple R files, upload the zip file. Our evaluation
 code looks like the following:

<pre>library(tidyverse)

source("mymain.R")

# read in train / test dataframes
train &lt;- readr::read_csv('train.csv')
test &lt;- readr::read_csv('test.csv', col_types = list(
    Weekly_Pred1 = col_double(),
    Weekly_Pred2 = col_double(),
    Weekly_Pred3 = col_double()
))

# save weighted mean absolute error WMAE
num_folds &lt;- 10
wae &lt;- tibble(
    model_one = rep(0, num_folds), 
    model_two = rep(0, num_folds), 
    model_three = rep(0, num_folds)
)

# time-series CV
for (t in 1:num_folds) {
  # *** THIS IS YOUR PREDICTION FUNCTION ***
  mypredict()
  
  # Load fold file 
  # You should add this to your training data in the next call 
  # to mypredict()
  fold_file &lt;- paste0('fold_', t, '.csv')
  new_test &lt;- readr::read_csv(fold_file)

  # extract predictions matching up to the current fold
  scoring_tbl &lt;- new_test %&gt;% 
      left_join(test, by = c('Date', 'Store', 'Dept'))
  
  # compute WMAE
  actuals &lt;- scoring_tbl$Weekly_Sales
  preds &lt;- select(scoring_tbl, contains('Weekly_Pred'))
  weights &lt;- if_else(scoring_tbl$IsHoliday.x, 5, 1)
  wae[t, ] &lt;- colSums(weights * abs(actuals - preds)) / sum(weights)
}

# save results to a file for grading
readr::write_csv(wae, 'Error.csv')
</pre>

  <ul>
  <li> <b>train.csv</b>: 5 columns ("Store", "Dept", "Date",
  "Weekly_Sales", "IsHoliday"), same as the train.csv file on Kaggle
  but ranging from 2010-02 to 2011-02.<br><br>
  </li><li> <b>test.csv</b>: 7 columns ("Store", "Dept", "Date",
  "IsHoliday", "Weekly_Pred1", "Weekly_Pred2", "Weekly_Pred3"), in
  the same format as the train.csv file on Kaggle ranging from 2011-03 to 2012-10 with 
  the last three columns being zero. <br><br>
  </li><li> <b>fold_1.csv</b>, ..., <b>fold_10.csv</b>: 5 columns ("Store", "Dept", "Date",
  "Weekly_Sales", "IsHoliday"), same as the train.csv file on Kaggle,
  and one for every two months starting from 2011-03 to 2012-10. 
  <br><br>
  </li><li> In your "mypredict" function, save the result from your three prediction models 
  in the corresponding rows in the data set "test". <br><br>
    </li><li> The evaluation metric is the same as <a href="https://www.kaggle.com/c/walmart-recruiting-store-sales-forecasting#evaluation" target="_blank">the one described on
  Kaggle</a>. 

</li></ul>
The evaluation process for Python code is similar. <br><br>

You are required to build <b>three</b> prediction models. Always include a
simple model, a model that doesn't require much training. For example,
predict sales for the next month by some average based on the previous
month or months.

</dd>
</dl>

<dt><b>Frequently Asked Questions</b></dt><dt>
</dt><dd>
  <ul>
    <li><i> <span style="text-decoration: underline;">Will you give us the training and test dataset?</span></i><br><br>

        The train.csv and test.csv for our evaluation are generated from the training data on Kaggle using the following code.  (You can download "train.csv.zip" from Kaggle or from the Resources page.)

<pre>library(lubridate)
library(tidyverse)

# read raw data and extract date column
train_raw &lt;- readr::read_csv(unz('train.csv.zip', 'train.csv'))
train_dates &lt;- train_raw$Date

# training data from 2010-02 to 2011-02, i.e. one year
start_date &lt;- ymd("2010-02-01")
end_date &lt;- start_date %m+% months(13)

# split dataset into training / testing
train_ids &lt;- which(train_dates &gt;= start_date &amp; train_dates &lt; end_date)
train = train_raw[train_ids, ]
test = train_raw[-train_ids, ]

# write the training results to a file
readr::write_csv(train, 'train.csv')

# Create the test.csv 
# Removes weekly sales and adds model pred columns.
test %&gt;% 
    select(-Weekly_Sales) %&gt;% 
    mutate(Weekly_Pred1 = 0, Weekly_Pred2 = 0, Weekly_Pred3 = 0) %&gt;% 
    readr::write_csv('test.csv')

# create 10-fold time-series CV
num_folds &lt;- 10
test_dates &lt;- train_dates[-train_ids]

# month 1 --&gt; 2011-03, and month 20 --&gt; 2012-10.
# Fold 1 : month 1 &amp; month 2, Fold 2 : month 3 &amp; month 4 ...
for (i in 1:num_folds) {
    # filter fold for dates
    start_date &lt;- ymd("2011-03-01") %m+% months(2 * (i - 1))
    end_date &lt;- ymd("2011-05-01") %m+% months(2 * (i - 1))
    test_fold &lt;- test %&gt;%
        filter(Date &gt;= start_date &amp; Date &lt; end_date)
    
    # write fold to a file
    readr::write_csv(test_fold, paste0('fold_', i, '.csv'))
}

</pre>
</li>
<li><i> <span style="text-decoration: underline;">What do we need to do in "mypredict()", a function that takes no input and produces no output either? </span></i><br><br>

In R, variables like train, test, and t are global parameters for "mypredict", so your predict function can access them, and even change their values using "&lt;&lt;-" for assigning values. 

<pre>test=function(){
  print(x^2)
  x &lt;&lt;- 2*x
}

x=3
test()
x

</pre>

Sourcing mymain.R basically loads in the function "mypredict". When running mypredict() for each t, you need to
do the following: 
<ul>
<li> If t &gt; 1, append new_test to training data;  </li>
<li> Update your model with the new training data, or only update your model periodically with enough new training data (up to you);</li>
<li> apply your current model to fill in the last three columns of "test" for the t-th two month period. <br><br></li>
</ul>



</li>

<li><i> <span style="text-decoration: underline;">Will you give us some materials of dealing with time series data sets?</span></i><br><br>

Check Walmart_Sample_Code.html on the Resouces page. <br><br>

R package [<a href="https://github.com/robjhyndman/forecast" target="_blank">forecast</a>] is designed for time series data. It's related to the stl package  used in Walmart_Sample_Code.html. <br><br>

On the other hand, if we create some features to describe the history at time t, e.g., x_t is a two-dimensional feature vector denoting the sales from the previous two weeks, then we can use linear regression models. <br><br>

</li><li><i> <span style="text-decoration: underline;">Some depts, like dept 99 of some stores, doesn't have any value in the first year. How should we predict without data, and how will you evaluate our prediction on missing values within the original training data?  
</span></i><br><br>

You can go through the discussion forum on Kaggle to check how others handle the problem of prediction with missing history.  The simplest solution is to predict it to be zero, or some kind of average (e.g., store average). Check Walmart_Sample_Code.html. <br><br>

Evaluation with missing data: if an observation is missing in 2010-03, we will skip that observation in the evaluation.

</li></ul></dd></div>
<hr>

</body></html>